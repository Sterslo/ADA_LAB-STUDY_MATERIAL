# ğŸ“– Sorting Algorithms - Study Notes

**Student Details:**
- Name: Prexit Joshi
- Roll Number: 233118
- Class: CSE 4th Semester, Section 2

---

## ğŸ“š Table of Contents
1. [Bubble Sort](#1-bubble-sort)
2. [Selection Sort](#2-selection-sort)
3. [Insertion Sort](#3-insertion-sort)
4. [Merge Sort](#4-merge-sort)
5. [Quick Sort](#5-quick-sort)
6. [Comparison Table](#comparison-table)

---

## 1. Bubble Sort
**File**: `bubblesort.cpp`

### ğŸ¯ Concept
Repeatedly compares adjacent elements and swaps them if they're in wrong order. The largest element "bubbles up" to the end in each pass.

### ğŸ“Š Complexity Analysis
- **Time Complexity**: 
  - Best Case: O(n) - when array is already sorted
  - Average Case: O(nÂ²)
  - Worst Case: O(nÂ²) - when array is reverse sorted
- **Space Complexity**: O(1) - in-place sorting
- **Stable**: Yes (maintains relative order of equal elements)

### ğŸ”„ Algorithm Steps
```
1. Start from the first element
2. Compare current element with next element
3. If current > next, swap them
4. Move to next pair
5. Repeat until end of array
6. Repeat entire process (n-1) times
```

### ğŸ“ Example (Dry Run)
**Input**: [64, 34, 25, 12, 22, 11, 90]

**Pass 1**: [34, 25, 12, 22, 11, 64, 90] â†’ 90 reaches end  
**Pass 2**: [25, 12, 22, 11, 34, 64, 90] â†’ 64 reaches position  
**Pass 3**: [12, 22, 11, 25, 34, 64, 90] â†’ 34 reaches position  
**Pass 4**: [12, 11, 22, 25, 34, 64, 90] â†’ 25 reaches position  
**Pass 5**: [11, 12, 22, 25, 34, 64, 90] â†’ Sorted!

### ğŸ’¡ Key Points
- âœ… Simple to understand and implement
- âœ… Works well for small datasets
- âŒ Very inefficient for large datasets
- âŒ Too many comparisons and swaps

### âš¡ Optimization
Add a flag to check if any swap happened in a pass. If no swap, array is sorted â†’ exit early.

---

## 2. Selection Sort
**File**: `selectionsort.cpp`

### ğŸ¯ Concept
Divides array into sorted and unsorted parts. Repeatedly finds minimum element from unsorted part and places it at beginning of unsorted part.

### ğŸ“Š Complexity Analysis
- **Time Complexity**: 
  - Best Case: O(nÂ²)
  - Average Case: O(nÂ²)
  - Worst Case: O(nÂ²)
- **Space Complexity**: O(1)
- **Stable**: No (can be made stable with modifications)

### ğŸ”„ Algorithm Steps
```
1. Set first position as minimum
2. Scan entire array to find actual minimum
3. Swap minimum with first position
4. Move to next position
5. Repeat for remaining unsorted part
```

### ğŸ“ Example (Dry Run)
**Input**: [64, 25, 12, 22, 11]

```
Step 1: [11, 25, 12, 22, 64] â†’ found min=11, swapped with 64
Step 2: [11, 12, 25, 22, 64] â†’ found min=12, swapped with 25
Step 3: [11, 12, 22, 25, 64] â†’ found min=22, swapped with 25
Step 4: [11, 12, 22, 25, 64] â†’ found min=25, already in place
```

### ğŸ’¡ Key Points
- âœ… Minimizes number of swaps (maximum n-1 swaps)
- âœ… Works well when write operation is costly
- âŒ Always O(nÂ²) - no best case optimization
- âŒ Not stable by default

---

## 3. Insertion Sort
**File**: `insertionsort.cpp`

### ğŸ¯ Concept
Builds final sorted array one item at a time. Picks element and inserts it at correct position in sorted part (like sorting playing cards).

### ğŸ“Š Complexity Analysis
- **Time Complexity**: 
  - Best Case: O(n) - when array is already sorted
  - Average Case: O(nÂ²)
  - Worst Case: O(nÂ²) - when array is reverse sorted
- **Space Complexity**: O(1)
- **Stable**: Yes

### ğŸ”„ Algorithm Steps
```
1. Start from second element (first is already "sorted")
2. Store current element as key
3. Compare key with elements in sorted part (left side)
4. Shift all larger elements one position right
5. Insert key at correct position
6. Repeat for all elements
```

### ğŸ“ Example (Dry Run)
**Input**: [12, 11, 13, 5, 6]

```
Initially: [12 | 11, 13, 5, 6]  (12 is sorted part)
Step 1:    [11, 12 | 13, 5, 6]  (insert 11)
Step 2:    [11, 12, 13 | 5, 6]  (insert 13)
Step 3:    [5, 11, 12, 13 | 6]  (insert 5)
Step 4:    [5, 6, 11, 12, 13]   (insert 6)
```

### ğŸ’¡ Key Points
- âœ… **Best for nearly sorted data** - O(n) performance
- âœ… Adaptive - efficient for small datasets
- âœ… Stable and in-place
- âœ… Online algorithm - can sort data as it arrives
- âŒ Inefficient for large datasets

### ğŸ“ Exam Tip
Remember: "Like sorting playing cards in your hand!"

---

## 4. Merge Sort
**File**: `mergeSort.cpp`

### ğŸ¯ Concept
**Divide and Conquer** algorithm. Divides array into halves recursively until single elements, then merges them back in sorted order.

### ğŸ“Š Complexity Analysis
- **Time Complexity**: 
  - Best Case: O(n log n)
  - Average Case: O(n log n)
  - Worst Case: O(n log n)
- **Space Complexity**: O(n) - requires extra space for merging
- **Stable**: Yes

### ğŸ”„ Algorithm Steps
```
DIVIDE PHASE:
1. Find middle point: mid = (left + right) / 2
2. Recursively divide left half: mergeSort(arr, left, mid)
3. Recursively divide right half: mergeSort(arr, mid+1, right)

CONQUER PHASE:
4. Merge both sorted halves
```

### ğŸ“ Example (Dry Run)
**Input**: [38, 27, 43, 3, 9, 82, 10]

```
                    [38, 27, 43, 3, 9, 82, 10]
                   /                           \
         [38, 27, 43, 3]                    [9, 82, 10]
         /            \                      /         \
    [38, 27]        [43, 3]            [9, 82]        [10]
    /     \         /     \            /     \
  [38]   [27]    [43]   [3]         [9]    [82]

MERGING:
  [27, 38]        [3, 43]            [9, 82]
         \            /                      \
       [3, 27, 38, 43]                  [9, 10, 82]
                    \                      /
                [3, 9, 10, 27, 38, 43, 82]
```

### ğŸ’¡ Key Points
- âœ… **Guaranteed O(n log n)** - best worst-case time complexity
- âœ… Stable sorting
- âœ… Excellent for **linked lists** (no random access needed)
- âœ… Used in **external sorting** (large files)
- âŒ Requires O(n) extra space
- âŒ Not in-place

### ğŸ“ Exam Important
**Recurrence Relation**: T(n) = 2T(n/2) + O(n)  
**Solution**: T(n) = O(n log n) using Master Theorem

---

## 5. Quick Sort
**Files**: `quicksort.cpp` (Recursive), `iterativequicksort.cpp` (Iterative)

### ğŸ¯ Concept
**Divide and Conquer** algorithm. Picks a pivot element and partitions array so that elements smaller than pivot are on left, greater on right. Recursively sorts both parts.

### ğŸ“Š Complexity Analysis
- **Time Complexity**: 
  - Best Case: O(n log n) - when pivot divides array evenly
  - Average Case: O(n log n)
  - Worst Case: O(nÂ²) - when array is already sorted and pivot is first/last element
- **Space Complexity**: 
  - Recursive: O(log n) - recursion stack
  - Iterative: O(log n) - explicit stack
- **Stable**: No

### ğŸ”„ Algorithm Steps
```
PARTITION:
1. Choose pivot (usually last element)
2. Place pivot at correct position
3. All smaller elements to left of pivot
4. All greater elements to right of pivot

RECURSION:
5. Recursively sort left subarray
6. Recursively sort right subarray
```

### ğŸ“ Example (Dry Run) - Lomuto Partition
**Input**: [10, 80, 30, 90, 40, 50, 70] | Pivot = 70

```
Initial:  [10, 80, 30, 90, 40, 50, 70]  pivot=70, i=-1

j=0: arr[0]=10 < 70 â†’ i=0, swap(10,10) â†’ [10, 80, 30, 90, 40, 50, 70]
j=1: arr[1]=80 > 70 â†’ no swap           â†’ [10, 80, 30, 90, 40, 50, 70]
j=2: arr[2]=30 < 70 â†’ i=1, swap(80,30) â†’ [10, 30, 80, 90, 40, 50, 70]
j=3: arr[3]=90 > 70 â†’ no swap           â†’ [10, 30, 80, 90, 40, 50, 70]
j=4: arr[4]=40 < 70 â†’ i=2, swap(80,40) â†’ [10, 30, 40, 90, 80, 50, 70]
j=5: arr[5]=50 < 70 â†’ i=3, swap(90,50) â†’ [10, 30, 40, 50, 80, 90, 70]

Final swap: swap(80, 70)                â†’ [10, 30, 40, 50, 70, 90, 80]
                                            Pivot at correct position!

Now recursively sort: [10, 30, 40, 50] and [90, 80]
```

### ğŸ’¡ Key Points
- âœ… **Fastest in practice** - excellent cache performance
- âœ… In-place sorting (O(log n) stack space only)
- âœ… Preferred for **arrays** (Merge sort for linked lists)
- âŒ Unstable
- âŒ O(nÂ²) worst case (can be avoided with random pivot)

### âš¡ Pivot Selection Strategies
1. **First element** - Simple but worst case for sorted arrays
2. **Last element** - Most common (used in our code)
3. **Middle element** - Better for partially sorted
4. **Random element** - Avoids worst case
5. **Median-of-three** - Best in practice

### ğŸ“ Exam Important
**Recurrence Relation**:
- Best/Average: T(n) = 2T(n/2) + O(n) â†’ O(n log n)
- Worst: T(n) = T(n-1) + O(n) â†’ O(nÂ²)

---

## ğŸ“Š Comparison Table

| Algorithm | Best | Average | Worst | Space | Stable | In-Place | Best Use Case |
|-----------|------|---------|-------|-------|--------|----------|---------------|
| **Bubble Sort** | O(n) | O(nÂ²) | O(nÂ²) | O(1) | âœ… Yes | âœ… Yes | Small/Nearly sorted |
| **Selection Sort** | O(nÂ²) | O(nÂ²) | O(nÂ²) | O(1) | âŒ No | âœ… Yes | Minimize swaps |
| **Insertion Sort** | O(n) | O(nÂ²) | O(nÂ²) | O(1) | âœ… Yes | âœ… Yes | Nearly sorted data |
| **Merge Sort** | O(n log n) | O(n log n) | O(n log n) | O(n) | âœ… Yes | âŒ No | Linked lists, large data |
| **Quick Sort** | O(n log n) | O(n log n) | O(nÂ²) | O(log n) | âŒ No | âœ… Yes | General purpose, arrays |

---

## ğŸ¯ Quick Decision Guide

**Choose Bubble Sort when:**
- ğŸ“ Learning/teaching sorting concepts
- ğŸ“Š Array is nearly sorted
- ğŸ”¢ Very small dataset (n < 10)

**Choose Selection Sort when:**
- ğŸ’¾ Memory writes are expensive
- ğŸ”¢ Small dataset with minimum swaps needed

**Choose Insertion Sort when:**
- âš¡ Data is nearly sorted or arrives online
- ğŸ”¢ Small dataset (n < 50)
- ğŸ“¦ Need stable sort with O(1) space

**Choose Merge Sort when:**
- ğŸ”— Sorting linked lists
- âœ… Need guaranteed O(n log n) performance
- ğŸ’¼ Stable sort is required
- ğŸ“‚ External sorting (large files)

**Choose Quick Sort when:**
- ğŸ† General purpose sorting
- ğŸ¯ Average case performance is priority
- ğŸ’¨ Cache-friendly sorting needed
- ğŸ“¦ Memory is limited (in-place sorting)

---

## ğŸ’­ Common Interview Questions

**Q1**: Why is Quick Sort faster than Merge Sort in practice despite same O(n log n) complexity?  
**A**: Quick Sort has better cache locality (in-place) and fewer data movements.

**Q2**: When does Quick Sort become O(nÂ²)?  
**A**: When pivot selection is poor (sorted array with first/last pivot) or when all elements are equal.

**Q3**: How to make Quick Sort stable?  
**A**: Use extra space to maintain order of equal elements (defeats purpose of Quick Sort).

**Q4**: Why is Merge Sort preferred for linked lists?  
**A**: No random access needed, and merging linked lists doesn't require extra space.

**Q5**: Which sorting algorithm is best for nearly sorted data?  
**A**: Insertion Sort - runs in O(n) time for nearly sorted data.

---

## âš™ï¸ Compilation & Execution

```bash
# Compile any sorting program
g++ -std=c++17 -O2 -o bubble.exe bubblesort.cpp
g++ -std=c++17 -O2 -o quick.exe quicksort.cpp

# Run
.\bubble.exe
.\quick.exe
```

---

## ğŸ“š Further Reading
- Master Theorem for solving recurrences
- Randomized Quick Sort to avoid O(nÂ²)
- Hybrid sorting (IntroSort = Quick + Heap + Insertion)
- Counting Sort, Radix Sort for special cases

---

**Remember**: No single sorting algorithm is best for all scenarios. Choose based on:
- Dataset size
- Data characteristics (sorted, random, duplicates)
- Memory constraints
- Stability requirements
- Time constraints
